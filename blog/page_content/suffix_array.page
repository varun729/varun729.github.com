%ORDER
1331753824
%$

%TITLE
%<Enter title here>
Suffix Array construction
%$

%DATE
Thursday, Mar 15, 2012
%$

%CONTENT
%<Enter content here, with all the html tags>
<p>
<b>Suffix array construction</b> is a problem on which a lot of work has already
been done. Researchers were able to get O(nlog(n)) time algorithms in the early
2000. But the constants involved in the algorithms were too large to be
feasible. And the problem remained unsolvable by consumer PCs, specifically in
the area of bioinformatics. Then in 2006, Karkkainen et al, came with an
algorithm, which was fast and consumed significantly lesser memory - allowing it
to be run on consumer machines. Using the suffix array, fast algorithms for
string alignment were developed and are used extensively in the bioinformatics
field. Bowtie is the most popular among the alignment softwares. Many others
have followed the path and come up with algorithms, which now perform similar or
better than Bowtie.
</p>
<p>
At Strand, I played a small role in implementing the alignment algorithm
(COBWEB). I worked on computing the suffix array for the human genome. I simply
implemented the algorithm described by Karkkainen et al, in their papers. I
learnt about the different challenges faced in implementing a algorithm which
runs on a large input. It was a learning experience and I thoroughly enjoyed it.
Having looked at a few algorithms during lectures at office, and also while
studying, I now have some ideas as to how suffix array can be computed for a
large input. Here I am going to discuss about the general idea of the algorithm.
</p>
<hr/>
<h3>Idea</h3>
<p>
Constructing the suffix array requires sorting all the suffixes of the given
input string. Say, if we are able to sort the suffixes somehow such that only a
few indices are left unsorted and they are close to their original location.
Thus the problem now is to place those suffixes in their correct position, and
then we have our suffix array.
</p>
<p>
<b>Now we have two problems to solve</b>. First is to show that it is
computationally inexpensive to construct an almost sorted suffix array. Second
is to show that exactly sorting an almost sorted suffix array is also
computationally inexpensive. Both these problems need a deeper insight and will
require significant reading.
</p>
<h4>First problem</h4>
<p>
To construct an almost sorted suffix array, we will use a randomized algorithm.
We will represent the suffixes as words of size c(any constant). While comparing
any two suffixes, if the first c characters are same, then we can compare the
next c characters. Depending on the size of the alphabet set, we can know the
possible number of words we can get, which is size^c. This can be possibly a
very large number. But we know that the only a small subset of this set of words
is actually found in our text. <b>If we can intelligently assign numbers to each
word, such that the numbers follow the lexicographical order, then the problem
of sorting is simplified to a very large extent.</b> Although this is not a easy
task, and is one of the main challenge to which a solution has to be found.
</p>
<p>
We can approach the sorting of these numbers in different ways. If the text is
small we can sort all the numbers at once. If the text is very large, e.g. the
human genome, then we can use blockwise sorting.
</p>
<h4>Second problem</h4>
<p>
Sorting an almost sorted suffix array, is a problem to which I currently have no
idea how to solve.
</p>
<p>
One thing which can be looked into is, how much different is the BWT constructed
from the inexact suffix array. If the BWT is reasonable and is erroneous in only
a small portion, then the speed attained from this algorithm could be worth
looking into. To compare this, construct the BWT from the inexact suffix array
and then reconstruct the text from this BWT. Compare this text with the original
text. Find the number of differences.
</p>
%$
